# Python Tests GitHub Actions Workflow for Hobbies Project

name: Python Tests

on:
  push:
    branches: [ main, develop ]
    paths:
      - '**/*.py'
      - 'requirements*.txt'
      - 'pyproject.toml'
      - 'uv.toml'
      - '.github/workflows/python-tests.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - '**/*.py'
      - 'requirements*.txt'
      - 'pyproject.toml'
      - 'uv.toml'
  workflow_dispatch:
  schedule:
    # Run tests every Sunday at 2 AM UTC
    - cron: '0 2 * * 0'

env:
  # Global environment variables
  PYTHONUNBUFFERED: 1
  FORCE_COLOR: 1

jobs:
  test:
    name: Test on Python ${{ matrix.python-version }} (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30

    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.9', '3.10', '3.11', '3.12']
        os: [ubuntu-latest, macos-latest]
        # Exclude combinations if needed for compatibility
        exclude:
          - os: macos-latest
            python-version: '3.9'

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Install uv
      uses: astral-sh/setup-uv@v1
      with:
        version: "latest"

    - name: Install dependencies
      run: |
        uv pip install --system pytest pytest-cov pytest-mock
        uv pip install --system -e .

    - name: Lint with flake8
      run: |
        uv pip install --system flake8
        # Stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=88 --statistics
      continue-on-error: true

    - name: Type checking with mypy
      run: |
        uv pip install --system mypy
        mypy .agent-os/ --ignore-missing-imports
      continue-on-error: true

    - name: Run tests with pytest
      run: |
        pytest \
          --cov=.agent-os \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term-missing \
          --cov-fail-under=60 \
          --junitxml=pytest.xml \
          --verbose
      env:
        # Environment variables for testing
        TESTING: true
        HOBBIES_ENV: test

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest'
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-results-${{ matrix.python-version }}-${{ matrix.os }}
        path: |
          pytest.xml
          htmlcov/
        retention-days: 30

    - name: Upload coverage reports
      uses: actions/upload-artifact@v3
      if: matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest'
      with:
        name: coverage-report
        path: |
          coverage.xml
          htmlcov/
        retention-days: 30

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: test
    timeout-minutes: 20

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: 3.11
        cache: 'pip'

    - name: Install uv
      uses: astral-sh/setup-uv@v1
      with:
        version: "latest"

    - name: Install dependencies
      run: |
        uv pip install --system pytest pytest-cov pytest-mock
        uv pip install --system -e .

    - name: Run integration tests
      run: |
        pytest tests/integration/ \
          --cov=.agent-os \
          --cov-report=xml \
          --verbose \
          -m "integration"
      env:
        TESTING: true
        HOBBIES_ENV: test

  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [test, integration-tests]
    if: always()

    steps:
    - name: Check test results
      run: |
        if [[ "${{ needs.test.result }}" != "success" ]]; then
          echo "‚ùå Unit tests failed"
          exit 1
        fi
        if [[ "${{ needs.integration-tests.result }}" != "success" ]]; then
          echo "‚ùå Integration tests failed"
          exit 1
        fi
        echo "‚úÖ All tests passed"

    - name: Quality gate passed
      run: echo "üéâ Quality gate passed! Ready for deployment."